{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee2ad1b-d745-4a7b-bc06-8fe8d614d8ff",
   "metadata": {},
   "source": [
    "# Federated Learning Case Study\n",
    "\n",
    "## 02. CICIDS 2017 Data Preparation \n",
    "\n",
    "In this notebook we prepare the CICIDS2017 dataset for further processing in our batch ML and federated learning scenarios. We use the CICIDS2017 improved dataset (noted in the paper ``Troubleshooting an Intrusion Detection Dataset: the CICIDS2017 Case Study''), available from https://downloads.distrinet-research.be/WTMC2021/index.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09a5f2",
   "metadata": {},
   "source": [
    "### 1. Preparing the CICIDS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918f9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e185f6-2e17-491b-b2dc-b66ba8d54874",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17868/4048683090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfeature_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcicids_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmonday_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcicids_directory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeature_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unicode_escape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtuesday_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcicids_directory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeature_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unicode_escape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mwednesday_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcicids_directory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeature_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unicode_escape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mthursday_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcicids_directory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeature_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unicode_escape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pa-legg\\.conda\\envs\\fedlearn\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pa-legg\\.conda\\envs\\fedlearn\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pa-legg\\.conda\\envs\\fedlearn\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cicids_directory = '../datasets/CICIDS2017-IMPROVED-DOWNLOAD'\n",
    "\n",
    "feature_files = os.listdir(cicids_directory)\n",
    "monday_features_df = pd.read_csv(cicids_directory + '/' + feature_files[1], encoding = 'unicode_escape', engine ='python')\n",
    "tuesday_features_df = pd.read_csv(cicids_directory + '/' + feature_files[3], encoding = 'unicode_escape', engine ='python')\n",
    "wednesday_features_df = pd.read_csv(cicids_directory + '/' + feature_files[4], encoding = 'unicode_escape', engine ='python')\n",
    "thursday_features_df = pd.read_csv(cicids_directory + '/' + feature_files[2], encoding = 'unicode_escape', engine ='python')\n",
    "friday_features_df = pd.read_csv(cicids_directory + '/' + feature_files[0], encoding = 'unicode_escape', engine ='python')\n",
    "feature_df = pd.concat([monday_features_df, tuesday_features_df, wednesday_features_df, thursday_features_df, friday_features_df])\n",
    "\n",
    "# Threshold to remove classes with less than THRESHOLD instances\n",
    "THRESHOLD = 0\n",
    "if THRESHOLD > 0:\n",
    "    dd = feature_df['Label'].value_counts()\n",
    "    feature_df = feature_df[feature_df['Label'].isin(dd[dd > THRESHOLD].index)]\n",
    "\n",
    "\n",
    "WRITE_DF_TO_PICKLE = False\n",
    "if WRITE_DF_TO_PICKLE:\n",
    "    filename = \"./full_cicids_df.pkl\"\n",
    "    print (\"Write DF to Pickle...\", filename)\n",
    "    feature_df.to_pickle(filename)\n",
    "    print (\"Writing DF to Pickle complete...\", filename)\n",
    "\n",
    "# Pre-processing to tidy up NaN values\n",
    "feature_df2 = feature_df.replace([np.inf, - np.inf], np.nan)\n",
    "feature_df2 = feature_df2.dropna()    \n",
    "label = feature_df2['Label']\n",
    "feature_df2 = feature_df2.drop(['Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Label'], axis=1)\n",
    "\n",
    "# Scaling of features to fit within defined range\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaled_features = StandardScaler().fit_transform(feature_df2.values)\n",
    "#scaled_features = MinMaxScaler().fit_transform(feature_df2.values)\n",
    "\n",
    "# Label Preprocessing\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_n = le.fit_transform(label.values)\n",
    "\n",
    "# Test / train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(scaled_features, label_n, stratify=label_n, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, label_n, stratify=label_n, test_size=0.2, random_state=42)\n",
    "print (\"Train:\", X_train.shape, y_train.shape)\n",
    "print (\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2631e7bb-1368-4144-a2f8-7bc2e34ea777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                                  1325655\n",
       "PortScan                                 127218\n",
       "DoS Hulk                                 126775\n",
       "DDoS                                      76098\n",
       "DoS GoldenEye                              6054\n",
       "DoS slowloris                              3201\n",
       "FTP-Patator                                3178\n",
       "DoS Slowhttptest - Attempted               2694\n",
       "SSH-Patator                                2384\n",
       "DoS Slowhttptest                           1394\n",
       "DoS slowloris - Attempted                  1365\n",
       "Bot - Attempted                            1176\n",
       "Web Attack - Brute Force - Attempted        971\n",
       "Bot                                         590\n",
       "Web Attack - XSS - Attempted                522\n",
       "DoS Hulk - Attempted                        463\n",
       "Web Attack - Brute Force                    121\n",
       "DoS GoldenEye - Attempted                    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = list(le.inverse_transform(y_train))\n",
    "pd.value_counts(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5234960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a762ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1679923, 79)\n",
      "(419981, 79)\n",
      "(1679923,)\n",
      "(419981,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4dcdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a87c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1679923, 79)\n",
      "(419981, 79)\n",
      "(1679923,)\n",
      "(419981,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186f0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1c3044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1679923, 79)\n",
      "(419981, 79)\n",
      "(1679923,)\n",
      "(419981,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93f0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fedlearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1a946a741f3f6200957dccf23404636c747a9eb7c96c9668153385b834240fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
