{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee2ad1b-d745-4a7b-bc06-8fe8d614d8ff",
   "metadata": {},
   "source": [
    "# Federated Learning Case Study\n",
    "\n",
    "## 05. FL CICIDS - Experimentation with different client configurations\n",
    "\n",
    "In this notebook, we devise a set of client configurations based on how the training data could be split across these. We use four schemes: individual IPs, individual attacks, group of IPs (based on similar OS), and group of attacks (based on name/type similarity).\n",
    "\n",
    "We use our previous model and can deploy each of these scenarios to the FL process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c4c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRATIFIED\n"
     ]
    }
   ],
   "source": [
    "### THIS SECTION NEEDS TO BE SET TO DETERMINE WHICH CONFIGURATION METHOD TO UTILISE\n",
    "\n",
    "AVAILABLE_METHODS = ['INDIVIDUAL_IP', 'GROUP_IP', 'INDIVIDUAL_ATTACK', 'GROUP_ATTACK', 'STRATIFIED']\n",
    "METHOD = AVAILABLE_METHODS[4]\n",
    "NUM_OF_STRATIFIED_CLIENTS = 10 # only applies to stratified method\n",
    "print (METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fefb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf064e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_pickle('full_cicids_df.pkl')\n",
    "# feature_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b41e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1680016, 76) (1680016,)\n",
      "Test: (420005, 76) (420005,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Pre-processing to tidy up NaN values\n",
    "feature_df2 = feature_df.replace([np.inf, - np.inf], np.nan)\n",
    "feature_df2 = feature_df2.dropna()    \n",
    "label = feature_df2['Label']\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_n = le.fit_transform(label.values)\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(feature_df2, label_n, stratify=label_n, test_size=0.2, random_state=42)\n",
    "#feature_df2 = feature_df2.drop(['Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Label'], axis=1)\n",
    "feature_df2 = feature_df2.drop(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Label'], axis=1)\n",
    "\n",
    "# Scaling of features to fit within defined range\n",
    "scaled_features = StandardScaler().fit_transform(feature_df2.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, label_n, stratify=label_n, test_size=0.2, random_state=42)\n",
    "\n",
    "print (\"Train:\", X_train.shape, y_train.shape)\n",
    "print (\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbccac9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known ip addresses: ['192.168.10.25', '192.168.10.15', '192.168.10.14', '192.168.10.8', '192.168.10.5', '192.168.10.9', '192.168.10.12', '192.168.10.16', '192.168.10.17', '192.168.10.19', '192.168.10.51', '192.168.10.50']\n",
      "os_groups: [['192.168.10.25'], ['192.168.10.15', '192.168.10.14', '192.168.10.8', '192.168.10.5', '192.168.10.9'], ['192.168.10.12', '192.168.10.16', '192.168.10.17', '192.168.10.19', '192.168.10.51', '205.174.165.66'], ['192.168.10.50', '205.174.165.68']]\n"
     ]
    }
   ],
   "source": [
    "known_ip_addresses = [ '192.168.10.25', '192.168.10.15', '192.168.10.14', '192.168.10.8', '192.168.10.5', '192.168.10.9', '192.168.10.12', '192.168.10.16', '192.168.10.17', '192.168.10.19', '192.168.10.51', '192.168.10.50']\n",
    "print (\"known ip addresses:\", known_ip_addresses)\n",
    "os_groups = [ ['192.168.10.25'],  #macOS\n",
    "                ['192.168.10.15', '192.168.10.14', '192.168.10.8', '192.168.10.5', '192.168.10.9'], #win\n",
    "                ['192.168.10.12', '192.168.10.16', '192.168.10.17', '192.168.10.19', '192.168.10.51', '205.174.165.66'], #ubuntu\n",
    "                ['192.168.10.50', '205.174.165.68'], # webserver\n",
    "                ]\n",
    "print (\"os_groups:\", os_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845c12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = label.unique()\n",
    "attack_groups = [['BENIGN'],\n",
    "                    ['DoS slowloris',\n",
    "       'DoS slowloris - Attempted', 'DoS Slowhttptest',\n",
    "       'DoS Slowhttptest - Attempted', 'DoS Hulk', 'DoS Hulk - Attempted',\n",
    "       'DoS GoldenEye', 'DDoS'],\n",
    "                    ['FTP-Patator', 'SSH-Patator', 'FTP-Patator - Attempted',\n",
    "       'SSH-Patator - Attempted'],\n",
    "                    ['Heartbleed'],\n",
    "                    ['Web Attack - Brute Force', 'Web Attack - Brute Force - Attempted', 'Web Attack - XSS - Attempted', 'Web Attack - XSS',\n",
    "       'Web Attack - Sql Injection'], \n",
    "                    ['Bot - Attempted', 'Bot'],\n",
    "                    ['PortScan'],\n",
    "                    ['Infiltration - Attempted', 'Infiltration']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe7d616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pa-legg\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fl_X_train = []\n",
    "fl_y_train = []\n",
    "\n",
    "if METHOD == AVAILABLE_METHODS[0]:\n",
    "    #### Group by individual IP (src and dst)\n",
    "    for i in known_ip_addresses:\n",
    "        new_i = [i]\n",
    "        print (new_i)\n",
    "        new_df_src = X_train_df[ X_train_df['Src IP'].isin(new_i) ]\n",
    "        new_df_dst = X_train_df[ X_train_df['Dst IP'].isin(new_i) ]\n",
    "        #new_df = pd.concat([new_df1, new_df2], axis=0)\n",
    "\n",
    "        X_np = np.vstack([ X_train[ new_df_src.index, : ], X_train[ new_df_dst.index, :] ])\n",
    "        y_np = np.hstack([ y_train[ new_df_src.index ], y_train[ new_df_dst.index ] ])\n",
    "\n",
    "        print (X_np.shape)\n",
    "        print (y_np.shape)\n",
    "\n",
    "        fl_X_train.append(X_np)\n",
    "        fl_y_train.append(y_np) \n",
    "elif METHOD == AVAILABLE_METHODS[1]:\n",
    "    #### Group by OS (src and dst)\n",
    "\n",
    "    for i in os_groups:\n",
    "        new_i = i\n",
    "        print (new_i)\n",
    "        new_df_src = X_train_df[ X_train_df['Src IP'].isin(new_i) ]\n",
    "        new_df_dst = X_train_df[ X_train_df['Dst IP'].isin(new_i) ]\n",
    "        #new_df = pd.concat([new_df1, new_df2], axis=0)\n",
    "\n",
    "        X_np = np.vstack([ X_train[ new_df_src.index, : ], X_train[ new_df_dst.index, :] ])\n",
    "        y_np = np.hstack([ y_train[ new_df_src.index ], y_train[ new_df_dst.index ] ])\n",
    "\n",
    "        print (X_np.shape)\n",
    "        print (y_np.shape)\n",
    "\n",
    "        fl_X_train.append(X_np)\n",
    "        fl_y_train.append(y_np) \n",
    "elif METHOD == AVAILABLE_METHODS[2]:\n",
    "    #### Group by individual attack\n",
    "    for i in attacks:\n",
    "        new_i = [i]\n",
    "        print (new_i)\n",
    "        new_df_attack = X_train_df[ X_train_df['Label'].isin(new_i) ]\n",
    "        #new_df = pd.concat([new_df1, new_df2], axis=0)\n",
    "\n",
    "        X_np = X_train[ new_df_attack.index, : ]\n",
    "        y_np = y_train[ new_df_attack.index ]\n",
    "\n",
    "        print (X_np.shape)\n",
    "        print (y_np.shape)\n",
    "\n",
    "        fl_X_train.append(X_np)\n",
    "        fl_y_train.append(y_np)\n",
    "elif METHOD == AVAILABLE_METHODS[3]:\n",
    "    #### Group by attack group\n",
    "\n",
    "    for i in attack_groups:\n",
    "        new_i = i\n",
    "        print (new_i)\n",
    "        new_df_attack_group = X_train_df[ X_train_df['Label'].isin(new_i) ]\n",
    "\n",
    "        X_np = X_train[ new_df_attack_group.index, : ]\n",
    "        y_np = y_train[ new_df_attack_group.index ]\n",
    "\n",
    "        print (X_np.shape)\n",
    "        print (y_np.shape)\n",
    "\n",
    "        fl_X_train.append(X_np)\n",
    "        fl_y_train.append(y_np) \n",
    "elif METHOD == AVAILABLE_METHODS[4]:\n",
    "    ## 1. STRATIFIED SAMPLING\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "\n",
    "    skf = StratifiedKFold(n_splits=NUM_OF_STRATIFIED_CLIENTS, shuffle=True, random_state=42)\n",
    "    skf.get_n_splits(X_train, y_train)\n",
    "\n",
    "    for _, test_index in skf.split(X_train, y_train):\n",
    "        fl_X_train.append(X_train[test_index])\n",
    "        fl_y_train.append(y_train[test_index]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cdad252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f53dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-11-12 23:35:48,896 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_OF_CLIENTS: 10\n",
      "Checking data split groups\n",
      "0 : X shape (168002, 76)  Y shape: (168002,)\n",
      "1 : X shape (168002, 76)  Y shape: (168002,)\n",
      "2 : X shape (168002, 76)  Y shape: (168002,)\n",
      "3 : X shape (168002, 76)  Y shape: (168002,)\n",
      "4 : X shape (168002, 76)  Y shape: (168002,)\n",
      "5 : X shape (168002, 76)  Y shape: (168002,)\n",
      "6 : X shape (168001, 76)  Y shape: (168001,)\n",
      "7 : X shape (168001, 76)  Y shape: (168001,)\n",
      "8 : X shape (168001, 76)  Y shape: (168001,)\n",
      "9 : X shape (168001, 76)  Y shape: (168001,)\n",
      "Importing Federated Learning environment...\n",
      "flwr 1.0.0\n",
      "numpy 1.22.4\n",
      "tf 2.10.0\n",
      "Deploy simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-11-12 23:35:56,026 | app.py:176 | Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 3733972992.0, 'memory': 7467945984.0}\n",
      "INFO flower 2022-11-12 23:35:56,027 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-11-12 23:35:56,028 | server.py:270 | Requesting initial parameters from one random client\n",
      "INFO flower 2022-11-12 23:36:00,579 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flower 2022-11-12 23:36:00,580 | server.py:88 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=19140)\u001b[0m Client ID: 6\n",
      "Server Evaluating...\n",
      "13126/13126 [==============================] - 20s 2ms/step - loss: 2.9706 - accuracy: 7.5713e-04\n",
      "13126/13126 [==============================] - 17s 1ms/step\n",
      "Prediction:  [[0.57045156 0.45580915 0.69168663 ... 0.52276516 0.3265823  0.5869563 ]\n",
      " [0.57216626 0.4544961  0.69329643 ... 0.521585   0.3260025  0.5864084 ]\n",
      " [0.55640197 0.4524274  0.6882688  ... 0.52614534 0.33807468 0.5898374 ]\n",
      " ...\n",
      " [0.5726697  0.45348892 0.69239515 ... 0.52135456 0.3270095  0.58595145]\n",
      " [0.5544972  0.44860122 0.6921621  ... 0.5366935  0.33859247 0.587453  ]\n",
      " [0.57258314 0.45366696 0.69197345 ... 0.52142084 0.32804763 0.58618194]] (420005, 25)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'confusion_matrix' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_772/4189727492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;31m# Start simulation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m fl.simulation.start_simulation(\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[0mclient_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclient_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0mnum_clients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_OF_CLIENTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fedlearn\\lib\\site-packages\\flwr\\simulation\\app.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[1;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;31m# Start training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m     hist = _fl(\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[0mserver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitialized_server\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitialized_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fedlearn\\lib\\site-packages\\flwr\\server\\app.py\u001b[0m in \u001b[0;36m_fl\u001b[1;34m(server, config)\u001b[0m\n\u001b[0;32m    177\u001b[0m ) -> History:\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"app_fit: losses_distributed %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses_distributed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"app_fit: metrics_distributed %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_distributed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fedlearn\\lib\\site-packages\\flwr\\server\\server.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_initial_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Evaluating initial parameters\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             log(\n",
      "\u001b[1;32m~\\.conda\\envs\\fedlearn\\lib\\site-packages\\flwr\\server\\strategy\\fedavg.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, server_round, parameters)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mparameters_ndarrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters_to_ndarrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0meval_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_ndarrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_res\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_772/4189727492.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(server_round, parameters, config)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserver_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Prediction: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"confusion_matrix:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'confusion_matrix' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# CHECK IF THIS REMAINS THE SAME OR CHANGED\n",
    "NUM_OF_CLIENTS = len(fl_X_train)\n",
    "print (\"NUM_OF_CLIENTS:\", NUM_OF_CLIENTS)\n",
    "\n",
    "NUM_OF_ROUNDS = 5\n",
    "\n",
    "print (\"Checking data split groups\")\n",
    "for i in range(len(fl_X_train)):\n",
    "    print (i, ':', \"X shape\", fl_X_train[i].shape, \" Y shape:\" , fl_y_train[i].shape)\n",
    "\n",
    "print (\"Importing Federated Learning environment...\")\n",
    "\n",
    "import os\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"tf\", tf.__version__)\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "class NumpyFlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, model, train_data, train_labels):\n",
    "        self.model = model\n",
    "        self.cid = cid\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Training...\")\n",
    "        self.model.fit(self.train_data, self.train_labels, epochs=1, batch_size=32)\n",
    "        print (\"Client \", self.cid, \"Training complete...\")\n",
    "        return self.model.get_weights(), len(self.train_data), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Evaluating...\")\n",
    "        loss, accuracy = self.model.evaluate(self.train_data, self.train_labels, batch_size=32)\n",
    "        print (\"Client \", self.cid, \"Evaluating complete...\", accuracy, loss)\n",
    "        return loss, len(self.train_data), {\"accuracy\": accuracy}\n",
    "    \n",
    "    def predict(self, incoming):\n",
    "        prediction = self.model.predict(incoming) \n",
    "        return prediction\n",
    "\n",
    "\n",
    "def client_fn(cid: str) -> NumpyFlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    #model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)\n",
    "    #model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    print (\"Client ID:\", cid)\n",
    "\n",
    "    model = Sequential([\n",
    "      #Flatten(input_shape=(79,1)),\n",
    "      Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "      Dense(256, activation='sigmoid'),\n",
    "      Dense(128, activation='sigmoid'), \n",
    "      #Dense(18, activation='sigmoid'),  \n",
    "      Dense(len(label.unique()), activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    partition_id = int(cid)\n",
    "    X_train_c = fl_X_train[partition_id]\n",
    "    y_train_c = fl_y_train[partition_id]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return NumpyFlowerClient(cid, model, X_train_c, y_train_c)\n",
    "\n",
    "\n",
    "print (\"Deploy simulation...\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def get_evaluate_fn(server_model):\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    # The `evaluate` function will be called after every round\n",
    "    def evaluate(server_round, parameters, config):\n",
    "        # Update model with the latest parameters\n",
    "        server_model.set_weights(parameters)\n",
    "        print (\"Server Evaluating...\")\n",
    "        loss, accuracy = server_model.evaluate(X_test, y_test)\n",
    "        \n",
    "        y_pred = server_model.predict(X_test)\n",
    "        print (\"Prediction: \", y_pred, y_pred.shape)\n",
    "        cmatrix = confusion_matrix(y_test, np.rint(y_pred))\n",
    "        print (\"confusion_matrix:\", cmatrix)\n",
    "        ConfusionMatrixDisplay(cmatrix)\n",
    "                        \n",
    "\n",
    "        print (\"Server Evaluating complete...\", accuracy, loss)\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "\n",
    "server_model = Sequential([\n",
    "      #Flatten(input_shape=(79,1)),\n",
    "      Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "      Dense(256, activation='sigmoid'),\n",
    "      Dense(128, activation='sigmoid'), \n",
    "      #Dense(18, activation='sigmoid'),  \n",
    "      Dense(len(label.unique()), activation='sigmoid')\n",
    "    ])\n",
    "server_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=2, #10,\n",
    "        min_evaluate_clients=2, #5,\n",
    "        min_available_clients=2, #10,\n",
    "        evaluate_fn=get_evaluate_fn(server_model),\n",
    "        #evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_OF_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_OF_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a082bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1a946a741f3f6200957dccf23404636c747a9eb7c96c9668153385b834240fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
